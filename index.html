<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>MIA Silent Voice</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
<style>
/* ... (Same CSS as before) ... */
@import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;600&display=swap');
* {margin:0; padding:0; box-sizing:border-box; font-family:"Poppins",sans-serif;}
:root {
  --text-color:#fff;
  --icon-color:#ACACBE;
  --icon-hover-bg:#5b5e71;
  --placeholder-color:#dcdcdc;
  --outgoing-chat-bg:#343541;
  --incoming-chat-bg:#444654;
  --outgoing-chat-border:#343541;
  --incoming-chat-border:#444654;
  --mic-active-color: #e55865;
}
.light-mode {
  --text-color:#343541;
  --icon-color:#a9a9bc;
  --icon-hover-bg:#f1f1f3;
  --placeholder-color:#6c6c6c;
  --outgoing-chat-bg:#fff;
  --incoming-chat-bg:#F7F7F8;
  --outgoing-chat-border:#fff;
  --incoming-chat-border:#D9D9E3;
}
body {background:var(--outgoing-chat-bg);}
.chat-container {overflow-y:auto; max-height:100vh; padding-bottom:150px;}
:where(.chat-container, textarea)::-webkit-scrollbar {width:6px;}
:where(.chat-container, textarea)::-webkit-scrollbar-track {background:var(--incoming-chat-bg); border-radius:25px;}
:where(.chat-container, textarea)::-webkit-scrollbar-thumb {background:var(--icon-color); border-radius:25px;}
.default-text {display:flex; align-items:center; justify-content:center; flex-direction:column; height:70vh; padding:0 10px; text-align:center; color:var(--text-color);}
.default-text h1 {font-size:3.3rem;}
.default-text p {margin-top:10px; font-size:1.1rem;}
.chat-container .chat {padding:25px 10px; display:flex; justify-content:center; color:var(--text-color);}
.chat-container .chat.outgoing {background:var(--outgoing-chat-bg); border:1px solid var(--outgoing-chat-border);}
.chat-container .chat.incoming {background:var(--incoming-chat-bg); border:1px solid var(--incoming-chat-border);}
.chat .chat-content {display:flex; max-width:1200px; width:100%; align-items:flex-start; justify-content:space-between;}
span.material-symbols-rounded {user-select:none; cursor:pointer;}
.chat .chat-content span {cursor:pointer; font-size:1.3rem; color:var(--icon-color); visibility:hidden;}
.chat:hover .chat-content:not(:has(.typing-animation), :has(.error)) span {visibility:visible;}
.chat .chat-details {display:flex; align-items:center;}
.chat .chat-details img {width:35px; height:35px; align-self:flex-start; object-fit:cover; border-radius:2px;}
.chat .chat-details p {white-space:pre-wrap; font-size:1.05rem; padding:0 50px 0 25px; color:var(--text-color); word-break:break-word;}
.chat .chat-details p.error {color:#e55865;}
.chat .typing-animation {padding-left:25px; display:inline-flex;}
.typing-animation .typing-dot {height:7px; width:7px; border-radius:50%; margin:0 3px; opacity:0.7; background:var(--text-color); animation:animateDots 1.5s var(--delay) ease-in-out infinite;}
.typing-animation .typing-dot:first-child {margin-left:0;}
@keyframes animateDots {0%,44%{transform:translateY(0px);} 28%{opacity:0.4; transform:translateY(-6px);} 44%{opacity:0.2;}}
.typing-container {position:fixed; bottom:0; width:100%; display:flex; padding:20px 10px; justify-content:center; background:var(--outgoing-chat-bg); border-top:1px solid var(--incoming-chat-border);}
.typing-container .typing-content {display:flex; max-width:950px; width:100%; align-items:flex-end;}
.typing-container .typing-textarea {width:100%; display:flex; position:relative;}
.typing-textarea textarea {resize:none; height:55px; width:100%; border:none; padding:15px 150px 15px 20px; color:var(--text-color); font-size:1rem; border-radius:4px; max-height:250px; overflow-y:auto; background:var(--incoming-chat-bg); outline:1px solid var(--incoming-chat-border);}
.typing-textarea textarea::placeholder {color:var(--placeholder-color);}
.typing-content span {width:55px; height:55px; display:flex; border-radius:4px; font-size:1.35rem; align-items:center; justify-content:center; color:var(--icon-color);}
.typing-textarea span {position:absolute; right:0; bottom:0; visibility:hidden;}
.typing-textarea textarea:valid ~ span {visibility:visible;}
.typing-controls {display:flex;}
.typing-controls span {margin-left:7px; font-size:1.4rem; background:var(--incoming-chat-bg); outline:1px solid var(--incoming-chat-border);}
.typing-controls span:hover {background:var(--icon-hover-bg);}
.typing-controls span.listening {
    color: var(--mic-active-color);
    animation: pulse 1.5s infinite;
    background: rgba(229, 88, 101, 0.1);
    border: 1px solid var(--mic-active-color);
}
@keyframes pulse { 0% { box-shadow: 0 0 0 0 rgba(229, 88, 101, 0.7); } 70% { box-shadow: 0 0 0 10px rgba(229, 88, 101, 0); } 100% { box-shadow: 0 0 0 0 rgba(229, 88, 101, 0); } }
</style>
</head>
<body>
<div class="chat-container">
  <div class="default-text"><h1>MIA</h1><p>Start a conversation</p></div>
</div>

<div class="typing-container">
  <div class="typing-content">
    <div class="typing-textarea">
      <textarea id="chat-input" spellcheck="false" placeholder="Enter a message" required></textarea>
      <span id="send-btn" class="material-symbols-rounded">send</span>
    </div>
    <div class="typing-controls">
      <span id="mic-btn" class="material-symbols-rounded">call</span>
      <span id="theme-btn" class="material-symbols-rounded">light_mode</span>
      <span id="delete-btn" class="material-symbols-rounded">delete</span>
    </div>
  </div>
</div>

<script>
const chatInput = document.querySelector("#chat-input");
const sendButton = document.querySelector("#send-btn");
const chatContainer = document.querySelector(".chat-container");
const themeButton = document.querySelector("#theme-btn");
const deleteButton = document.querySelector("#delete-btn");
const micButton = document.querySelector("#mic-btn");

const API_URL = "/api/chat";
const SYSTEM_PROMPT = "Act as a robot... (same prompt)";

// STATE
let autoListenMode = false;
let isProcessing = false;
let mediaRecorder;
let audioChunks = [];
let silenceTimer;
let audioContext;
let analyser;
let microphone;
let javascriptNode;

let conversation = JSON.parse(localStorage.getItem("conversation")) || [{ role:"system", content: SYSTEM_PROMPT }];

function loadChats(){
  chatContainer.innerHTML = localStorage.getItem("all-chats") || `<div class="default-text"><h1>MIA</h1><p>Start a conversation</p></div>`;
  const theme = localStorage.getItem("themeColor");
  document.body.classList.toggle("light-mode", theme==="light_mode");
  themeButton.innerText = document.body.classList.contains("light-mode")?"dark_mode":"light_mode";
}
loadChats();
function saveConversation(){ localStorage.setItem("conversation", JSON.stringify(conversation)); }
function saveAllChats(){ localStorage.setItem("all-chats", chatContainer.innerHTML); }
function createChatElement(content,className){ const div=document.createElement("div"); div.classList.add("chat",className); div.innerHTML=content; return div; }

// --- PLAY AUDIO ---
function playAudioBlob(base64Audio) {
    const audio = new Audio(base64Audio);
    audio.onended = () => {
        isProcessing = false;
        if(autoListenMode) startRecording();
    };
    audio.play().catch(e => {
        isProcessing = false;
        if(autoListenMode) startRecording();
    });
}

// --- SILENT RECORDER LOGIC (Replaces SpeechRecognition) ---

async function startRecording() {
    if(isProcessing) return; // Don't record while thinking
    
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        micButton.classList.add("listening");
        chatInput.placeholder = "Listening (Silent)...";

        // 1. Setup MediaRecorder to capture audio
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];
        
        mediaRecorder.ondataavailable = event => {
            audioChunks.push(event.data);
        };

        mediaRecorder.onstop = async () => {
            // Processing audio...
            if(!autoListenMode && !isProcessing) return; // Stopped manually

            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            if(audioBlob.size < 1000) {
                 // Too small, probably empty
                 if(autoListenMode) startRecording();
                 return;
            }

            isProcessing = true; // Stop listening while we process
            micButton.classList.remove("listening");
            chatInput.placeholder = "Processing...";
            
            // Convert to Base64
            const reader = new FileReader();
            reader.readAsDataURL(audioBlob);
            reader.onloadend = () => {
                const base64Audio = reader.result; // Data URL
                sendToBackend(base64Audio);
            };
        };

        mediaRecorder.start();

        // 2. Setup AudioContext for Silence Detection
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioContext.createAnalyser();
        microphone = audioContext.createMediaStreamSource(stream);
        javascriptNode = audioContext.createScriptProcessor(2048, 1, 1);

        analyser.smoothingTimeConstant = 0.8;
        analyser.fftSize = 1024;

        microphone.connect(analyser);
        analyser.connect(javascriptNode);
        javascriptNode.connect(audioContext.destination);

        let silenceStart = Date.now();
        let hasSpoken = false;

        javascriptNode.onaudioprocess = function() {
            if(!autoListenMode) return; // Stop processing if disabled

            const array = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(array);
            let values = 0;
            const length = array.length;
            for (let i = 0; i < length; i++) { values += array[i]; }
            const average = values / length;

            // Threshold for "Speaking" (adjust if needed, 20 is decent for voice)
            if (average > 20) {
                silenceStart = Date.now();
                hasSpoken = true;
                chatInput.placeholder = "I hear you...";
            } else {
                // Check if silence duration exceeded 2 seconds
                if (hasSpoken && Date.now() - silenceStart > 2000) {
                    stopRecordingAndSend();
                }
            }
        }

    } catch(err) {
        console.error("Mic Error:", err);
        alert("Microphone access denied or error.");
        autoListenMode = false;
        micButton.classList.remove("listening");
    }
}

function stopRecordingAndSend() {
    if(mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop(); // This triggers onstop above
    }
    // Clean up Audio Context
    if(audioContext) audioContext.close();
    if(javascriptNode) javascriptNode.disconnect();
    if(microphone) microphone.disconnect();
}

// --- BUTTON HANDLER ---
micButton.addEventListener("click", () => {
    if (location.protocol !== 'https:' && location.hostname !== 'localhost') {
        alert("HTTPS Required."); return;
    }

    if(autoListenMode) {
        // STOP
        autoListenMode = false;
        isProcessing = false;
        stopRecordingAndSend(); // Cleanup
        micButton.classList.remove("listening");
        chatInput.placeholder = "Enter a message";
    } else {
        // START
        autoListenMode = true;
        startRecording();
    }
});

// --- API SEND ---
async function sendToBackend(base64Audio) {
  // UI Update
  const tempUserDiv = createChatElement(`<div class="chat-content"><div class="chat-details"><img src="https://i.ibb.co/XZGD889v/user1.png"><p>...</p></div></div>`, "outgoing");
  chatContainer.appendChild(tempUserDiv);
  chatContainer.scrollTo(0,chatContainer.scrollHeight);

  const miaDiv = createChatElement(`<div class="chat-content"><div class="chat-details"><img src="https://i.ibb.co/PvkyhHBw/3464.png"><div class="typing-animation"><div class="typing-dot"></div><div class="typing-dot"></div><div class="typing-dot"></div></div></div></div>`,"incoming");
  chatContainer.appendChild(miaDiv);

  try {
    const res = await fetch(API_URL, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ 
        messages: conversation,
        audioInput: base64Audio // Sending audio!
      })
    });

    const data = await res.json();
    if(data.action === "ignore") {
        // Silence was recorded but ignored
        tempUserDiv.remove();
        miaDiv.remove();
        if(autoListenMode) startRecording();
        return;
    }
    if(data.error) throw new Error(data.error);

    // Update UI with actual transcribed text
    tempUserDiv.querySelector("p").textContent = data.user_transcript;
    conversation.push({ role: "user", content: data.user_transcript });
    
    // Update UI with AI reply
    conversation.push({ role:"assistant", content: data.content });
    saveConversation();

    miaDiv.querySelector(".typing-animation").remove();
    const p = document.createElement("p");
    p.textContent = data.content;
    miaDiv.querySelector(".chat-details").appendChild(p);
    saveAllChats();
    chatContainer.scrollTo(0,chatContainer.scrollHeight);

    // Play Response
    if(data.audio) playAudioBlob(data.audio);

  } catch(err) {
    console.error(err);
    miaDiv.querySelector(".typing-animation").remove();
    miaDiv.innerHTML = `<p style="color:red">Error: ${err.message}</p>`;
    isProcessing = false;
    // Don't auto restart on error to avoid loops
  }
}

sendButton.addEventListener("click",()=>{ if(chatInput.value) { /* Handle text send logic if needed */ } });
// Note: This example focuses on Voice. For text, you'd replicate the non-audio backend call logic.
</script>
</body>
</html>
